{
  "provider": "openai",
  "model_id": "gpt-4o-mini",
  "test_name": "tool_call",
  "recorded_at": "2025-11-28T20:52:35.630142+05:30",
  "request_hash": "ba85a940bafe829c2a5ae5e6e88f24eb904903808cc6b69658aa57d8acf3e8c6",
  "request": {
    "messages": [
      {
        "role": "human",
        "parts": [
          {
            "Text": "Use the read_file tool to read the contents of the file 'go.mod'. Make sure to provide the 'path' parameter with the value 'go.mod'."
          }
        ]
      }
    ],
    "model_id": "gpt-4o-mini",
    "options": {
      "tools_count": 1
    }
  },
  "response_data": {
    "choices": [
      {
        "finish_reason": "tool_calls",
        "index": 0,
        "logprobs": {
          "content": null,
          "refusal": null
        },
        "message": {
          "annotations": [],
          "audio": {
            "data": "",
            "expires_at": 0,
            "id": "",
            "transcript": ""
          },
          "content": "",
          "function_call": {
            "arguments": "",
            "name": ""
          },
          "refusal": "",
          "role": "assistant",
          "tool_calls": [
            {
              "custom": {
                "input": "",
                "name": ""
              },
              "function": {
                "arguments": "{\"path\":\"go.mod\"}",
                "name": "read_file"
              },
              "id": "call_S9ZfADkTGwwGGETtAyebx6Lt",
              "type": "function"
            }
          ]
        }
      }
    ],
    "created": 1764343354,
    "id": "chatcmpl-CguaoIUcIkPeRetOkYCxKmoaL22gB",
    "model": "gpt-4o-mini-2024-07-18",
    "object": "chat.completion",
    "service_tier": "default",
    "system_fingerprint": "fp_eca0ce8298",
    "usage": {
      "completion_tokens": 15,
      "completion_tokens_details": {
        "accepted_prediction_tokens": 0,
        "audio_tokens": 0,
        "reasoning_tokens": 0,
        "rejected_prediction_tokens": 0
      },
      "prompt_tokens": 81,
      "prompt_tokens_details": {
        "audio_tokens": 0,
        "cached_tokens": 0
      },
      "total_tokens": 96
    }
  },
  "chunk_count": 1
}